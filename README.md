# OCR Benchmark Framework

é’ˆå¯¹LLMè§†è§‰èƒ½åŠ›çš„OCRåŸºå‡†æµ‹è¯•æ¡†æž¶ï¼Œæ”¯æŒV1æ–‡æœ¬æå–å’ŒV2ç»“æž„åŒ–æå–ä¸¤ç§æ¨¡å¼ã€‚

## ðŸš€ 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

```bash
# 1. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 2. é…ç½®APIå¯†é’¥
cp env.example .env
# ç¼–è¾‘ .env å¡«å…¥ä½ çš„API keys

# 3. è¿è¡Œbenchmark
python3 main.py -v v1 -m gemini -id gemini-2.0-flash-exp

# 4. æŸ¥çœ‹ç»“æžœ
streamlit run app.py
```

## ðŸ“‹ å®Œæ•´æ“ä½œæµç¨‹

### âš–ï¸ å…¬å¹³è¯„æµ‹ä¸Žé²æ£’æ€§ä¼˜åŒ– (Fair Evaluation)

é¡¹ç›®å†…ç½®äº†é’ˆå¯¹ä¸åŒæ¨¡åž‹è¾“å‡ºé£Žæ ¼çš„é²æ£’æ€§ä¼˜åŒ–æ–¹æ¡ˆï¼Œç¡®ä¿è¯„æµ‹ç»“æžœçœŸå®žåæ˜ è§†è§‰èƒ½åŠ›ï¼š

- **Prompt å¼ºåŒ–**ï¼šå†…ç½® Prompt ä½¿ç”¨äº†â€œç²¾ç¡®æ•°æ®å‘˜â€æŒ‡ä»¤ï¼Œå¼ºåˆ¶æ¨¡åž‹å…³æ³¨å‹¾é€‰æ¡†çŠ¶æ€ï¼ˆV/X/O/Circleï¼‰è€Œéžç›²çŒœï¼Œå¹¶ä¸¥æ ¼é™åˆ¶è¾“å‡ºæ ¼å¼ã€‚
- **V1 æ–‡æœ¬å½’ä¸€åŒ–**ï¼šè‡ªåŠ¨å¤„ç†æ ‡ç‚¹ç¬¦å·ã€å…¨åŠè§’è½¬æ¢ã€ç‰¹æ®Šå­—ç¬¦å¹²æ‰°ã€‚å³ä¾¿æ¨¡åž‹è‡ªåŠ¨ä¿®æ­£äº†æ ‡ç‚¹æˆ–æ·»åŠ äº†åºå·ï¼Œä¹Ÿä¸ä¼šå› æ­¤æ‰£åˆ†ã€‚
- **V2 æ¨¡ç³ŠåŒ¹é…**ï¼š
  - **é”®åå¯¹é½**ï¼šæ”¯æŒä¸­è‹±æ–‡é”®åè‡ªåŠ¨æ˜ å°„ï¼ˆå¦‚è¯†åˆ«å‡ºâ€œå¿ƒè„ç—…â€ä¼šè‡ªåŠ¨å¯¹é½åˆ°â€œHeart Diseaseâ€ï¼‰ã€‚
  - **é€»è¾‘å€¼å½’ä¸€åŒ–**ï¼šå°† `True/False`, `Yes/No`, `Checked/Unchecked`, `V/X` ç»Ÿä¸€æ˜ å°„ä¸º `Y/N` è¿›è¡Œæ¯”å¯¹ã€‚
  - **å®žä½“æ¨¡ç³ŠåŒ¹é…**ï¼šæ”¯æŒå­ä¸²åŒ¹é…ï¼Œè§£å†³è¯†åˆ«æ–‡æœ¬å¾®å°å·®å¼‚å¯¼è‡´çš„å¾—åˆ†æ–­å´–ã€‚

### æ­¥éª¤1ï¼šåˆ¶ä½œSchemaé…ç½®ï¼ˆV2æ¨¡å¼ï¼‰

**å¦‚æžœä½¿ç”¨V1æ¨¡å¼ï¼ˆçº¯æ–‡æœ¬OCRï¼‰ï¼Œè·³è¿‡æ­¤æ­¥éª¤ã€‚**

#### 1.1 å¤åˆ¶æ¨¡æ¿

```bash
# ä½¿ç”¨åŒ»ç–—è¡¨å•æ¨¡æ¿ï¼ˆé»˜è®¤ï¼‰
cp schemas/medical_form.yaml schemas/my_schema.yaml

# æˆ–ä½¿ç”¨å‘ç¥¨æ¨¡æ¿
cp schemas/invoice.yaml schemas/my_schema.yaml
```

#### 1.2 ç¼–è¾‘Schema

ç¼–è¾‘ `schemas/my_schema.yaml`ï¼š

```yaml
schema_name: "my_document"
version: "v2"
description: "ä½ çš„æ–‡æ¡£ç±»åž‹æè¿°"

fields:
  # å­—æ®µ1ï¼šåˆ†ç±»å­—å…¸ï¼ˆY/Né€‰æ‹©ã€å•é€‰é¢˜ç­‰ï¼‰
  - name: "field1_name"
    type: "categorical_dict"     # ç±»åž‹ï¼šcategorical_dict, entity_list, text_dict, numerical_dict
    evaluation: "accuracy"        # è¯„ä¼°ï¼šaccuracy, f1, pairing, exact_match
    weight: 0.3                   # æƒé‡ï¼š0-1ä¹‹é—´ï¼Œä¼šè‡ªåŠ¨å½’ä¸€åŒ–
    description: "å­—æ®µè¯´æ˜Ž"
    
  # å­—æ®µ2ï¼šå®žä½“åˆ—è¡¨ï¼ˆå…³é”®è¯æå–ç­‰ï¼‰
  - name: "field2_name"
    type: "entity_list"
    evaluation: "f1"
    weight: 0.4
    description: "å­—æ®µè¯´æ˜Ž"

# LLMæå–prompt
prompt_template: |
  è¯·åˆ†æžè¿™ä¸ªæ–‡æ¡£ï¼Œè¿”å›žJSONå¯¹è±¡åŒ…å«ï¼š
  1. 'field1_name': {...}
  2. 'field2_name': [...]
  åªè¿”å›žJSONï¼Œä¸è¦markdownä»£ç å—ã€‚
```

**å­—æ®µç±»åž‹é€ŸæŸ¥ï¼š**
- `categorical_dict`: å­—å…¸ `{"q1": "Y", "q2": "N"}` â†’ ç”¨äºŽé€‰æ‹©é¢˜
- `entity_list`: åˆ—è¡¨ `["å®žä½“1", "å®žä½“2"]` â†’ ç”¨äºŽå…³é”®è¯æå–
- `text_dict`: å­—å…¸ `{"å­—æ®µ": "æ–‡æœ¬"}` â†’ ç”¨äºŽå­—æ®µé…å¯¹
- `numerical_dict`: å­—å…¸ `{"total": 100.5}` â†’ ç”¨äºŽæ•°å€¼å­—æ®µ

**è¯„ä¼°æ–¹æ³•é€ŸæŸ¥ï¼š**
- `accuracy`: ç²¾ç¡®åŒ¹é… â†’ ç”¨äºŽcategorical_dict
- `f1`: F1åˆ†æ•° â†’ ç”¨äºŽentity_list
- `pairing`: æ¨¡ç³ŠåŒ¹é… â†’ ç”¨äºŽtext_dict
- `exact_match`: ä¸¥æ ¼ç›¸ç­‰ â†’ ç”¨äºŽnumerical_dict

#### 1.3 éªŒè¯Schema

```bash
python3 -c "
from schemas.schema_base import SchemaLoader
schema = SchemaLoader.load_schema('schemas/my_schema.yaml')
print('âœ“ SchemaåŠ è½½æˆåŠŸ')
print(f'å­—æ®µ: {[f.name for f in schema.fields]}')
print(f'æƒé‡: {schema.weights}')
"
```

### æ­¥éª¤2ï¼šåˆ¶ä½œæ ‡å‡†ç­”æ¡ˆï¼ˆGround Truthï¼‰

#### 2.1 å‡†å¤‡å›¾ç‰‡

å°†å›¾ç‰‡æ”¾åˆ° `data/` ç›®å½•ï¼š
```bash
cp your_images/*.png data/
```

#### 2.2 åˆ›å»ºGround Truth JSON

**V1æ¨¡å¼** - åˆ›å»º `data/sample_gt.json`ï¼š
```json
[
  {
    "file_name": "sample.png",
    "text": "è¯†åˆ«çš„æ–‡æœ¬å†…å®¹..."
  }
]
```

**V2æ¨¡å¼** - åˆ›å»º `data/sample_gt_v2.json`ï¼ˆç»“æž„è¦åŒ¹é…schemaï¼‰ï¼š
```json
[
  {
    "file_name": "sample.png",
    "field1_name": {"q1": "Y", "q2": "N"},
    "field2_name": ["å®žä½“1", "å®žä½“2"]
  }
]
```

#### 2.3 è¾…åŠ©æ ‡æ³¨ï¼ˆå¯é€‰ï¼‰

ä½¿ç”¨Geminiè‡ªåŠ¨ç”Ÿæˆåˆç¨¿ï¼Œç„¶åŽäººå·¥ä¿®æ­£ï¼š

```bash
# V1æ¨¡å¼
python3 utils/prep_labels.py -v v1
# ç”Ÿæˆ labeling_v1/*.md æ–‡ä»¶

# V2æ¨¡å¼
python3 utils/prep_labels.py -v v2
# ç”Ÿæˆ labeling_v2/*.md æ–‡ä»¶

# åœ¨Cursor/VSCodeä¸­ï¼š
# 1. æ‰“å¼€.mdæ–‡ä»¶
# 2. æŒ‰Cmd+Shift+Vé¢„è§ˆï¼ˆå¯çœ‹åˆ°å›¾ç‰‡ï¼‰
# 3. ç¼–è¾‘æ–‡æœ¬/JSON
# 4. ä¿å­˜

# åŒæ­¥å›žGT JSON
python3 utils/sync_to_gt.py -v v1  # æˆ– -v v2
```

### æ­¥éª¤3ï¼šè¿è¡ŒBenchmark

#### 3.1 åŸºæœ¬ç”¨æ³•

```bash
# V1æ¨¡å¼ï¼ˆæ–‡æœ¬OCRï¼‰
python3 main.py -v v1 -m gemini -id gemini-2.0-flash-exp

# V2æ¨¡å¼ï¼ˆç»“æž„åŒ–æå–ï¼Œé»˜è®¤åŒ»ç–—è¡¨å•ï¼‰
python3 main.py -v v2 -m gemini -id gemini-2.0-flash-exp
```

#### 3.2 æ”¯æŒçš„æ¨¡åž‹

```bash
# Gemini
python3 main.py -v v1 -m gemini -id gemini-2.0-flash-exp

# OpenAI GPT-4V
python3 main.py -v v1 -m openai -id gpt-4o

# OpenAI GPT-5ï¼ˆå¦‚é‡åˆ° Request timed outï¼Œå»ºè®®æé«˜è¶…æ—¶ + å¼€å¯é‡è¯•ï¼‰
# export OPENAI_TIMEOUT_SECONDS=180
# export OPENAI_OCR_MAX_ATTEMPTS=3
# export OPENAI_VERBOSE_RETRIES=true
python3 main.py -v v1 -m openai -id gpt-5

# Qwen
python3 main.py -v v1 -m qwen -id qwen-vl-max

# æµ‹è¯•ç”¨Dummyæ¨¡åž‹
python3 main.py -v v1 -m dummy -id dummy
```

#### 3.4 OpenAI è¶…æ—¶/é‡è¯•å‚æ•°ï¼ˆå¯é€‰ï¼‰

å°†ä¸‹åˆ—é…ç½®å†™å…¥ä½ çš„ `.env`ï¼ˆæˆ–åœ¨ shell é‡Œ `export`ï¼‰ï¼š

- `OPENAI_TIMEOUT_SECONDS`ï¼šå•æ¬¡è¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 120
- `OPENAI_MAX_RETRIES`ï¼šopenai-python SDK å†…éƒ¨é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤ 2
- `OPENAI_OCR_MAX_ATTEMPTS`ï¼šæœ¬é¡¹ç›®å¤–å±‚é‡è¯•æ¬¡æ•°ï¼ˆå¯¹ timeout/5xx/429 ç”Ÿæ•ˆï¼‰ï¼Œé»˜è®¤ 3
- `OPENAI_RETRY_BACKOFF_SECONDS` / `OPENAI_RETRY_BACKOFF_MAX_SECONDS`ï¼šæŒ‡æ•°é€€é¿å‚æ•°
- `OPENAI_VERBOSE_RETRIES`ï¼šæ‰“å°æ›´è¯¦ç»†çš„é‡è¯•/å›žé€€æ—¥å¿—ï¼ˆtrue/falseï¼‰
- `OPENAI_FALLBACK_TO_CHAT`ï¼šæ˜¯å¦å…è®¸ `responses` å¤±è´¥åŽå›žé€€åˆ° `chat.completions`
- `OPENAI_BASE_URL`ï¼šå¯é€‰ï¼Œä»£ç†/ç½‘å…³åœ°å€

#### 3.3 ä½¿ç”¨è‡ªå®šä¹‰Schemaï¼ˆV2æ¨¡å¼ï¼‰

é¡¹ç›®æ”¯æŒâ€œåŒç”¨æ¨¡å¼â€ï¼Œä½ å¯ä»¥é€‰æ‹©ä½¿ç”¨å†…ç½®çš„åŒ»ç–—è¡¨å•é€»è¾‘ï¼Œæˆ–è€…ä½¿ç”¨æ›´çµæ´»çš„ YAML Schemaã€‚

**æ–¹å¼ Aï¼šä½¿ç”¨å†…ç½®åŒ»ç–—è¡¨å•é€»è¾‘ï¼ˆé»˜è®¤ï¼‰**
æ­¤æ¨¡å¼ä½¿ç”¨ `utils/prompts.py` ä¸­é¢„å®šä¹‰çš„æç¤ºè¯å’Œ `evaluators/evaluator_v2.py` ä¸­çš„ç¡¬ç¼–ç è¯„ä¼°é€»è¾‘ã€‚
```bash
python3 main.py -v v2 -m gemini -id gemini-2.0-flash-exp
```

**æ–¹å¼ Bï¼šä½¿ç”¨è‡ªå®šä¹‰ Schemaï¼ˆæŽ¨èï¼ŒåŠ¨æ€åŠ è½½ï¼‰**
é€šè¿‡ `-s` å‚æ•°æŒ‡å®š YAML é…ç½®æ–‡ä»¶ã€‚ç³»ç»Ÿä¼šè‡ªåŠ¨ä»Ž YAML ä¸­è¯»å– `prompt_template`ï¼Œå¹¶ä½¿ç”¨é€šç”¨çš„ `SchemaBasedEvaluator` è¿›è¡Œè¯„ä¼°ã€‚è¿™ç§æ–¹å¼æ›´é€‚åˆæ‰©å±•åˆ°ä¸åŒç±»åž‹çš„æ–‡æ¡£ï¼ˆå¦‚å‘ç¥¨ã€åˆåŒï¼‰ã€‚
```bash
python3 main.py -v v2 -s schemas/medical_form.yaml -m gemini -id gemini-2.0-flash-exp
```

> **æç¤º**ï¼šå½“ä½ ä½¿ç”¨ `-s` æ¨¡å¼æ—¶ï¼Œç³»ç»Ÿå°†**å®Œå…¨ç»•è¿‡** `utils/prompts.py` ä¸­çš„æç¤ºè¯ï¼Œè½¬è€Œä½¿ç”¨ YAML ä¸­çš„é…ç½®ã€‚



### æ­¥éª¤4ï¼šæŸ¥çœ‹è¯„ä¼°ç»“æžœ

#### 4.1 å¯åŠ¨Dashboard

```bash
streamlit run app.py
```

æµè§ˆå™¨è‡ªåŠ¨æ‰“å¼€ `http://localhost:8501`

#### 4.2 DashboardåŠŸèƒ½

**Tab 1: ðŸ“Š Leaderboardï¼ˆæŽ’è¡Œæ¦œï¼‰**
- æŸ¥çœ‹æ‰€æœ‰æ¨¡åž‹çš„æŽ’å
- å¯¹æ¯”å„é¡¹æŒ‡æ ‡
- æŸ¥çœ‹æ±‡æ€»ç»Ÿè®¡

**V1æŒ‡æ ‡ï¼š**
- CERï¼ˆå­—ç¬¦é”™è¯¯çŽ‡ï¼‰- è¶Šä½Žè¶Šå¥½
- WERï¼ˆè¯é”™è¯¯çŽ‡ï¼‰- è¶Šä½Žè¶Šå¥½
- NEDï¼ˆå½’ä¸€åŒ–ç¼–è¾‘è·ç¦»ï¼‰- è¶Šä½Žè¶Šå¥½
- Precisionï¼ˆç²¾ç¡®çŽ‡ï¼‰- è¶Šé«˜è¶Šå¥½
- Recallï¼ˆå¬å›žçŽ‡ï¼‰- è¶Šé«˜è¶Šå¥½
- BoW F1ï¼ˆè¯è¢‹F1ï¼‰- è¶Šé«˜è¶Šå¥½
- Exact Matchï¼ˆå®Œå…¨åŒ¹é…çŽ‡ï¼‰- è¶Šé«˜è¶Šå¥½

**V2æŒ‡æ ‡ï¼š**
- Weighted Scoreï¼ˆåŠ æƒæ€»åˆ†ï¼‰- è¶Šé«˜è¶Šå¥½
- Logical Accï¼ˆé€»è¾‘å€¼å‡†ç¡®çŽ‡ï¼‰
- Disease Accï¼ˆç–¾ç—…çŠ¶æ€å‡†ç¡®çŽ‡ï¼‰
- Entity F1ï¼ˆå®žä½“F1åˆ†æ•°ï¼‰
- Entity Precision & Recall
- Pairing Accï¼ˆå­—æ®µé…å¯¹å‡†ç¡®çŽ‡ï¼‰

**Tab 2: ðŸ” Detailed Viewï¼ˆè¯¦ç»†å¯¹æ¯”ï¼‰**
- é€‰æ‹©å›¾ç‰‡æŸ¥çœ‹åŽŸå›¾
- å¯¹æ¯”Ground Truthå’Œé¢„æµ‹ç»“æžœ
- å¤šæ¨¡åž‹å¹¶æŽ’å¯¹æ¯”

**Tab 3: ðŸ“ˆ Statistical Analysisï¼ˆç»Ÿè®¡åˆ†æžï¼‰**
- é€‰æ‹©ä¸¤ä¸ªæ¨¡åž‹å¯¹æ¯”
- æŸ¥çœ‹p-valueã€ç½®ä¿¡åŒºé—´
- åˆ¤æ–­å·®å¼‚æ˜¯å¦æ˜¾è‘—
- ç®±çº¿å›¾å¯è§†åŒ–

**Tab 4: ðŸ“¤ Exportï¼ˆå¯¼å‡ºï¼‰**
- **LaTeXè¡¨æ ¼**ï¼šç›´æŽ¥å¤åˆ¶åˆ°è®ºæ–‡
- **CSVæ–‡ä»¶**ï¼šç”¨äºŽExcelåˆ†æž
- **JSONæ–‡ä»¶**ï¼šåŽŸå§‹æ•°æ®

### æ­¥éª¤5ï¼šå¯¼å‡ºè®ºæ–‡ç”¨çš„è¡¨æ ¼

#### 5.1 åœ¨Dashboardä¸­å¯¼å‡º

1. æ‰“å¼€Dashboard â†’ Exportæ ‡ç­¾
2. è¾“å…¥è¡¨æ ¼æ ‡é¢˜
3. ç‚¹å‡»"Generate LaTeX"
4. å¤åˆ¶ä»£ç åˆ°è®ºæ–‡

#### 5.2 LaTeXè¡¨æ ¼ç¤ºä¾‹

```latex
\begin{table}
\caption{OCR Benchmark Results (V2 Mode)}
\begin{tabular}{lrrrrr}
\toprule
Model ID & Weighted Score & Logical Acc & Entity F1 & Pairing Acc & Samples \\
\midrule
gemini-2.0 & 0.8742 & 0.9286 & 0.8500 & 0.8125 & 1 \\
gpt-4o & 0.8521 & 0.9143 & 0.8200 & 0.8000 & 1 \\
\bottomrule
\end{tabular}
\label{tab:results}
\end{table}
```

#### 5.3 ç»Ÿè®¡åˆ†æžç»“æžœ

åœ¨Statistical Analysisæ ‡ç­¾ï¼š
1. é€‰æ‹©æŒ‡æ ‡ï¼ˆå¦‚Weighted Scoreï¼‰
2. é€‰æ‹©ä¸¤ä¸ªæ¨¡åž‹
3. è¿è¡Œç»Ÿè®¡æµ‹è¯•
4. è®°å½•p-valueå’Œç½®ä¿¡åŒºé—´

**è®ºæ–‡ä¸­å¯ä»¥å†™**ï¼š
> Model A achieved significantly higher performance than Model B (Weighted Score: 0.87 Â± 0.03 vs. 0.81 Â± 0.04, p < 0.001).

## ðŸ’¡ å®žç”¨æŠ€å·§

### Schemaè®¾è®¡å»ºè®®

**æƒé‡åˆ†é…ï¼š**
- æ ¸å¿ƒå­—æ®µï¼ˆå¦‚é‡‘é¢ã€IDï¼‰ï¼š0.3-0.4
- é‡è¦å­—æ®µï¼ˆå¦‚æ—¥æœŸã€åç§°ï¼‰ï¼š0.2-0.3
- æ¬¡è¦å­—æ®µï¼ˆå¦‚å¤‡æ³¨ï¼‰ï¼š0.1-0.2

**å­—æ®µæ•°é‡ï¼š**
- å»ºè®®2-6ä¸ªå­—æ®µ
- å¤ªå¤šä¼šå½±å“è¯„ä¼°æ•ˆçŽ‡

**è¯„ä¼°æ–¹æ³•é€‰æ‹©ï¼š**
| å­—æ®µå†…å®¹ | æŽ¨èæ–¹æ³• | ç¤ºä¾‹ |
|---------|---------|------|
| Y/Né€‰é¡¹ã€å•é€‰é¢˜ | `accuracy` | {"q1": "Y"} |
| å…³é”®è¯ã€å®žä½“æå– | `f1` | ["NPC", "RT"] |
| æ–‡æœ¬é…å¯¹ã€åœ°å€ | `pairing` | {"åœ°å€": "åŒ—äº¬å¸‚..."} |
| é‡‘é¢ã€IDå· | `exact_match` | {"total": 100.5} |

### Ground Truthåˆ¶ä½œå»ºè®®

**è´¨é‡æŽ§åˆ¶ï¼š**
- è‡³å°‘2äººæ ‡æ³¨å…³é”®æ ·æœ¬
- ä½¿ç”¨`prep_labels.py`ç”Ÿæˆåˆç¨¿èŠ‚çœæ—¶é—´
- åœ¨Markdowné¢„è§ˆä¸­å¯¹ç…§å›¾ç‰‡ä¿®æ­£

**æ ·æœ¬æ•°é‡ï¼š**
- æœ€å°‘ï¼š10-20ä¸ªï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
- å»ºè®®ï¼š30-50ä¸ªï¼ˆç»Ÿè®¡æœ‰æ•ˆï¼‰
- è®ºæ–‡ï¼š50+ä¸ªï¼ˆå­¦æœ¯æ ‡å‡†ï¼‰

### å¤šæ¨¡åž‹å¯¹æ¯”

æ‰¹é‡è¿è¡Œå¤šä¸ªæ¨¡åž‹ï¼š
```bash
# åˆ›å»ºè„šæœ¬ run_all.sh
for model_id in gemini-2.0-flash-exp gpt-4o qwen-vl-max; do
  python3 main.py -v v2 -m gemini -id $model_id
done

# è¿è¡Œ
bash run_all.sh

# åœ¨Dashboardä¸­å¯¹æ¯”æ‰€æœ‰ç»“æžœ
streamlit run app.py
```

## ðŸ”§ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•æ·»åŠ æ–°æ–‡æ¡£ç±»åž‹ï¼Ÿ
1. å¤åˆ¶schemaæ¨¡æ¿ï¼š`cp schemas/medical_form.yaml schemas/æ–°æ–‡æ¡£.yaml`
2. ç¼–è¾‘å­—æ®µå®šä¹‰å’Œprompt
3. å‡†å¤‡å¯¹åº”çš„ground truth
4. ä¿®æ”¹main.pyä½¿ç”¨æ–°schema

### Q2: ä¸ºä»€ä¹ˆæˆ‘çš„ç»“æžœè¿™ä¹ˆä½Žï¼Ÿ
- æ£€æŸ¥Ground Truthæ˜¯å¦æ­£ç¡®
- ç¡®è®¤promptæ˜¯å¦æ¸…æ™°
- V2æ¨¡å¼ï¼šæ£€æŸ¥JSONæ ¼å¼æ˜¯å¦åŒ¹é…schema
- å°è¯•ä¸åŒçš„æ¨¡åž‹å¯¹æ¯”

### Q3: å¦‚ä½•å¤„ç†ä¸­è‹±æ–‡æ··åˆæ–‡æ¡£ï¼Ÿ
- æ¡†æž¶å®Œå…¨æ”¯æŒä¸­è‹±æ–‡æ··åˆ
- Ground Truthä¸­ç›´æŽ¥å†™ä¸­è‹±æ–‡
- Schemaå­—æ®µåå»ºè®®ç”¨è‹±æ–‡ï¼Œæè¿°å¯ä»¥ç”¨ä¸­æ–‡

### Q4: Dashboardæ˜¾ç¤ºNo resultsæ€Žä¹ˆåŠžï¼Ÿ
- ç¡®è®¤benchmarkå·²è¿è¡Œï¼š`ls results/preds_*.json`
- æ£€æŸ¥æ–‡ä»¶å‘½åæ ¼å¼ï¼š`preds_v1_æ¨¡åž‹å.json`
- ç¡®è®¤Ground Truthå­˜åœ¨ï¼š`ls data/sample_gt*.json`

### Q5: å¦‚ä½•æŠ¥å‘Šç½®ä¿¡åŒºé—´ï¼Ÿ
åœ¨Statistical Analysisæ ‡ç­¾ï¼š
1. è¿è¡ŒBootstrapç½®ä¿¡åŒºé—´
2. è®°å½•95% CIèŒƒå›´
3. è®ºæ–‡ä¸­å†™ï¼š`0.87 (95% CI: [0.84, 0.90])`

### Q6: LaTeXè¡¨æ ¼å¯¼å‡ºåŽæ ¼å¼æœ‰é—®é¢˜ï¼Ÿ
- ç¡®ä¿ä½¿ç”¨`booktabs`åŒ…ï¼š`\usepackage{booktabs}`
- æ£€æŸ¥åˆ—å¯¹é½ï¼š`lrrr`ï¼ˆl=å·¦å¯¹é½ï¼Œr=å³å¯¹é½ï¼‰
- æ‰‹åŠ¨è°ƒæ•´å°æ•°ä½æ•°

### Q7: å¦‚ä½•åŠ å¿«benchmarké€Ÿåº¦ï¼Ÿ
- ä½¿ç”¨æ›´å¿«çš„æ¨¡åž‹ï¼ˆå¦‚gemini-flash vs gemini-proï¼‰
- å‡å°‘æ ·æœ¬æ•°é‡å¿«é€Ÿæµ‹è¯•
- ä½¿ç”¨dummyæ¨¡åž‹è°ƒè¯•æµç¨‹

## ðŸ“ é¡¹ç›®ç»“æž„

```
OCR_benchmark/
â”œâ”€â”€ data/                          # å›¾ç‰‡å’ŒGround Truth
â”‚   â”œâ”€â”€ *.png                      # æµ‹è¯•å›¾ç‰‡
â”‚   â”œâ”€â”€ sample_gt.json             # V1 Ground Truth
â”‚   â””â”€â”€ sample_gt_v2.json          # V2 Ground Truth
â”‚
â”œâ”€â”€ schemas/                       # Schemaé…ç½®ï¼ˆV2æ¨¡å¼ï¼‰
â”‚   â”œâ”€â”€ medical_form.yaml          # åŒ»ç–—è¡¨å•schema
â”‚   â””â”€â”€ invoice.yaml               # å‘ç¥¨schemaï¼ˆç¤ºä¾‹ï¼‰
â”‚
â”œâ”€â”€ models/                        # æ¨¡åž‹å®žçŽ°
â”‚   â”œâ”€â”€ gemini_model.py
â”‚   â”œâ”€â”€ openai_model.py
â”‚   â””â”€â”€ qwen_model.py
â”‚
â”œâ”€â”€ evaluators/                    # è¯„ä¼°å™¨
â”‚   â”œâ”€â”€ evaluator.py               # V1è¯„ä¼°å™¨
â”‚   â”œâ”€â”€ evaluator_v2.py            # V2è¯„ä¼°å™¨ï¼ˆåŒ»ç–—è¡¨å•ï¼‰
â”‚   â”œâ”€â”€ schema_evaluator.py        # é€šç”¨Schemaè¯„ä¼°å™¨
â”‚   â”œâ”€â”€ metrics.py                 # æŒ‡æ ‡è®¡ç®—
â”‚   â””â”€â”€ statistical_tests.py       # ç»Ÿè®¡æ£€éªŒ
â”‚
â”œâ”€â”€ results/                       # è¾“å‡ºç»“æžœ
â”‚   â””â”€â”€ preds_v1_*.json            # é¢„æµ‹ç»“æžœ
â”‚
â”œâ”€â”€ utils/                         # å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ prompts.py                 # Promptå®šä¹‰
â”‚   â”œâ”€â”€ prep_labels.py             # è¾…åŠ©æ ‡æ³¨
â”‚   â””â”€â”€ sync_to_gt.py              # åŒæ­¥GT
â”‚
â”œâ”€â”€ main.py                        # ä¸»è¿è¡Œè„šæœ¬
â”œâ”€â”€ app.py                         # Streamlit Dashboard
â””â”€â”€ requirements.txt               # ä¾èµ–åŒ…
```

## ðŸ“š å‘½ä»¤é€ŸæŸ¥è¡¨

```bash
# å®‰è£…
pip install -r requirements.txt

# é…ç½®APIå¯†é’¥
cp env.example .env
# ç¼–è¾‘ .env å¡«å…¥å¯†é’¥

# è¿è¡Œbenchmark
python3 main.py -v v1 -m gemini -id gemini-2.0-flash-exp    # V1æ¨¡å¼
python3 main.py -v v2 -m gemini -id gemini-2.0-flash-exp    # V2æ¨¡å¼

# è¾…åŠ©åˆ¶ä½œæ ‡æ³¨
python3 utils/prep_labels.py -v v2
python3 utils/sync_to_gt.py -v v2

# å¯åŠ¨Dashboard
streamlit run app.py

# éªŒè¯Schemaï¼ˆV2æ¨¡å¼ï¼‰
python3 -c "from schemas.schema_base import SchemaLoader; print(SchemaLoader.load_schema('schemas/medical_form.yaml'))"
```

## ðŸ“Š æŒ‡æ ‡è¯´æ˜Ž

**V1æŒ‡æ ‡ï¼š** CERâ†“, WERâ†“, NEDâ†“, Precisionâ†‘, Recallâ†‘, BoW F1â†‘, Exact Matchâ†‘  
**V2æŒ‡æ ‡ï¼š** Weighted Scoreâ†‘, Logical Accâ†‘, Entity F1â†‘, Pairing Accâ†‘

ï¼ˆâ†‘è¶Šé«˜è¶Šå¥½ï¼Œâ†“è¶Šä½Žè¶Šå¥½ï¼‰

---

**å®Œæ•´æŠ€æœ¯æ–‡æ¡£**: è§ `IMPLEMENTATION_SUMMARY.md`

